{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f83137-f9be-485a-96d5-7c1d1845bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa3dae-bf22-4763-a992-2ca8596f349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 1: Loading in Data \n",
    "######\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435d164-86d8-4264-b3e2-9cea1e7ec756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the air pollution readingS for nox emissions at the Exeter Roadside AURN air pollution monitoring stations\n",
    "#The details of the station itself can be found here: \n",
    "airPollutionTargetVector = pd.read_feather(\"AllDataset/airPollutionTargetVector/nox/Exeter Roadside.feather\")\n",
    "airPollutionTargetVector[\"Timestamp\"] = pd.to_datetime(airPollutionTargetVector[\"Timestamp\"], utc=True)\n",
    "display(airPollutionTargetVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9da47d-e1de-48fb-8b8e-7f4fb926220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(30,5))\n",
    "axes.scatter(airPollutionTargetVector[\"Timestamp\"], airPollutionTargetVector[\"nox\"], s=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767fd7e1-ee01-4247-abd6-e6d7a771ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#However as there is a considerable amount of data avaliable, this is going to be reduced to just 2018.\n",
    "airPollutionTargetVector[\"Year\"] = airPollutionTargetVector[\"Timestamp\"].dt.year\n",
    "airPollutionTargetVector_2018 = airPollutionTargetVector[airPollutionTargetVector[\"Year\"] == 2018]\n",
    "airPollutionTargetVector_2018 = airPollutionTargetVector_2018.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e3514-ab77-4d97-af09-49a21ac87342",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(30,5))\n",
    "axes.scatter(airPollutionTargetVector_2018[\"Timestamp\"], airPollutionTargetVector_2018[\"nox\"], s=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bc1fc2-f84f-4ab5-8e05-bf6733411118",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 2: Summary Statistics of the data\n",
    "######\n",
    "######\n",
    "\n",
    "airPollutionTargetVector_2018[\"nox\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ebf43-1b4a-4c0b-a0a3-5e564e01eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 3: Find the Timestamps that are missing. \n",
    "######\n",
    "######\n",
    "time_range = pd.DataFrame(pd.date_range('2018-01-01T00:00:00.000Z', '2018-12-12T23:00:00.000Z', freq='H')).rename(columns={0:\"Timestamp\"})\n",
    "airPollutionTargetVector_2018_missingTimestamps = pd.merge(airPollutionTargetVector_2018, time_range, on=\"Timestamp\", how=\"right\")\n",
    "airPollutionTargetVector_2018_missingTimestamps = airPollutionTargetVector_2018_missingTimestamps[airPollutionTargetVector_2018_missingTimestamps['nox'].isna()]\n",
    "missingTimestamps = airPollutionTargetVector_2018_missingTimestamps[[\"Timestamp\"]]\n",
    "display(missingTimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04014c68-4d86-4fa6-9884-ec974945f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see there are 297 values across the year that the monitoring stations broke down where we have no estimate for what the air pollution \n",
    "#like at the station \n",
    "\n",
    "#Therefore we are going to build a machine learning model that can learn a relationship and predict what the air pollution would look like in those\n",
    "#timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a6798-29f5-4422-9885-a244da7a3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 4: Model with temporal variables \n",
    "######\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663501a-b189-4795-8a72-659a85782ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first model that we can build could just look at the time of the day and make an estimate \n",
    "\n",
    "airPollutionTargetVector_2018[\"Hour\"] = airPollutionTargetVector_2018[\"Timestamp\"].dt.hour\n",
    "airPollutionTargetVector_2018[\"Day\"] = airPollutionTargetVector_2018[\"Timestamp\"].dt.day\n",
    "airPollutionTargetVector_2018[\"Week\"] = airPollutionTargetVector_2018[\"Timestamp\"].dt.isocalendar().week\n",
    "airPollutionTargetVector_2018[\"Month\"] = airPollutionTargetVector_2018[\"Timestamp\"].dt.month\n",
    "display(airPollutionTargetVector_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bc743-b4db-4d16-a846-d99993428f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression model \n",
    "\n",
    "\n",
    "#In this case we are going to make a linear regression model where the target variable is the nox concentrations at a given time\n",
    "y = airPollutionTargetVector_2018[\"nox\"].to_numpy()\n",
    "#The feature vector, what we are going to try and predict the pollution \n",
    "X = airPollutionTargetVector_2018[[\"Hour\", \"Day\", \"Week\", \"Month\"]].to_numpy()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "\n",
    "display(\"The score of the model is: \" + str(reg.score(X, y)))\n",
    "display(\"The coefficient is: \" + str(reg.coef_) + \" The intercept was: \" + str(reg.intercept_))\n",
    "\n",
    "\n",
    "#The model predicts that on a monday at 8AM, in the third week of a January that the air pollution would be 53.67 ug/m^3\n",
    "display(\"Example Predicition:\" + str(reg.predict(np.array([[8, 1, 3, 1]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555c7c9-53b8-40f9-b9fd-4cf2a844fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#However as we can see the score for the other predicitions isnt great, we only achieve a score of 0.03\n",
    "#As we know that air pollution can be affected by a range of different conditions, such as the wind speed, traffic, land use, we want to include those\n",
    "#in our models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e437fc-10b3-485c-bb7a-a536bd5982a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 5: Read in additional data \n",
    "######\n",
    "######\n",
    "\n",
    "airPollutionFeatureVector = pd.read_feather(\"AllDataset/airPollutionFeatureVector/Grid_173560.feather\")\n",
    "airPollutionFeatureVector[\"Timestamp\"] = pd.to_datetime(airPollutionFeatureVector[\"Timestamp\"], utc=True)\n",
    "display(airPollutionFeatureVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92221a03-e8bc-43d9-ba27-7a498bf7db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to combine all the data into a single dataframe to make it easier to use \n",
    "airPollutionData = pd.merge(airPollutionTargetVector_2018, airPollutionFeatureVector, on=\"Timestamp\")\n",
    "display(airPollutionData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650a390-8dd9-4a1e-8312-019b42df2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 6: Using Traffic Data \n",
    "######\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7612f-b5ff-448c-b2a4-1f688d4a503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this case we are going to make a linear regression model where the target variable is the nox concentrations at a given time\n",
    "y = airPollutionData[\"nox\"].to_numpy()\n",
    "#The feature vector, what we are going to try and predict the pollution \n",
    "X = airPollutionData[[\"Hour\", \"Day\", \"Week\", \"Month\", \"HGV Score\", \"LGV Score\", \"Bicycle Score\", \"Bus and Coach Score\", \"Car and Taxi Score\"]].to_numpy()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "display(\"The score of the model is: \" + str(reg.score(X, y)))\n",
    "#this time when we include additional data from the traffic aspects our performance improves to 0.2! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbc618-fc80-453b-96ad-82d057d69d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 7: Using Met Data\n",
    "######\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f2a8d-e5bf-4273-967d-434c5ed5661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What if we added in met data, such as the wind speed?\n",
    "\n",
    "y = airPollutionData[\"nox\"].to_numpy()\n",
    "#The feature vector, what we are going to try and predict the pollution \n",
    "X = airPollutionData[[\"Hour\", \"Day\", \"Week\", \"Month\", \"HGV Score\", \"LGV Score\", \"Bicycle Score\", \"Bus and Coach Score\", \"Car and Taxi Score\",\n",
    "                     '100m_u_component_of_wind',\n",
    " '100m_v_component_of_wind',\n",
    " '10m_u_component_of_wind',\n",
    " '10m_v_component_of_wind',\n",
    " '2m_dewpoint_temperature',\n",
    " '2m_temperature',\n",
    " 'instantaneous_10m_wind_gust',\n",
    " 'surface_pressure',\n",
    " 'total_column_rain_water',]].to_numpy()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "display(\"The score of the model is: \" + str(reg.score(X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91a287-7095-48d3-ae4a-ffdf76bd7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This time our performance has increased to 0.45!\n",
    "\n",
    "######\n",
    "###### Stage 8: Fill in missing data\n",
    "######\n",
    "######\n",
    "\n",
    "\n",
    "#Lets now try and fill in the missing values that we dont have an air pollution measurement for\n",
    "time_range = pd.DataFrame(pd.date_range('2018-01-01T00:00:00.000Z', '2018-12-12T23:00:00.000Z', freq='H')).rename(columns={0:\"Timestamp\"})\n",
    "airPollutionTargetVector_2018_missingTimestamps = pd.merge(airPollutionTargetVector_2018, time_range, on=\"Timestamp\", how=\"right\")\n",
    "airPollutionTargetVector_2018_missingTimestamps = airPollutionTargetVector_2018_missingTimestamps[airPollutionTargetVector_2018_missingTimestamps['nox'].isna()]\n",
    "#airPollutionTargetVector_2018_missingTimestamps = airPollutionTargetVector_2018_missingTimestamps[airPollutionTargetVector_2018_missingTimestamps[\"Year\"] == 2018]\n",
    "missingTimestamps = airPollutionTargetVector_2018_missingTimestamps[[\"Timestamp\"]]\n",
    "display(missingTimestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83f43e-9d11-4e9d-9d43-9c1a164b81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingTimestampsFeatureVectors = airPollutionFeatureVector[airPollutionFeatureVector[\"Timestamp\"].isin(missingTimestamps[\"Timestamp\"].tolist())].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4676e-d8c3-4084-a942-9e6bf4207e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingTimestampsFeatureVectors[\"Hour\"] = missingTimestampsFeatureVectors[\"Timestamp\"].dt.hour\n",
    "missingTimestampsFeatureVectors[\"Day\"] = missingTimestampsFeatureVectors[\"Timestamp\"].dt.day\n",
    "missingTimestampsFeatureVectors[\"Week\"] = missingTimestampsFeatureVectors[\"Timestamp\"].dt.isocalendar().week\n",
    "missingTimestampsFeatureVectors[\"Month\"] = missingTimestampsFeatureVectors[\"Timestamp\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af6f94-e99e-42b9-a28c-91dc86522cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = missingTimestampsFeatureVectors[[\"Hour\", \"Day\", \"Week\", \"Month\", \"HGV Score\", \"LGV Score\", \"Bicycle Score\", \"Bus and Coach Score\", \"Car and Taxi Score\",\n",
    "                     '100m_u_component_of_wind',\n",
    " '100m_v_component_of_wind',\n",
    " '10m_u_component_of_wind',\n",
    " '10m_v_component_of_wind',\n",
    " '2m_dewpoint_temperature',\n",
    " '2m_temperature',\n",
    " 'instantaneous_10m_wind_gust',\n",
    " 'surface_pressure',\n",
    " 'total_column_rain_water',]].to_numpy()\n",
    "missingAirPollutionPredicitions = reg.predict(X)\n",
    "display(X.shape)\n",
    "display(missingAirPollutionPredicitions.shape)\n",
    "display(missingTimestamps.shape)\n",
    "missingTimestamps[\"nox Predictions\"] = missingAirPollutionPredicitions\n",
    "display(missingTimestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b392f-4f0d-445c-9f43-43696dc080df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, figsize=(30,5))\n",
    "airPollutionTargetVector_2018 = airPollutionTargetVector[airPollutionTargetVector[\"Year\"] == 2018]\n",
    "axes.scatter(airPollutionTargetVector_2018[\"Timestamp\"], airPollutionTargetVector_2018[\"nox\"], s=0.75)\n",
    "axes.scatter(missingTimestamps[\"Timestamp\"], missingTimestamps[\"nox Predictions\"], color=\"green\", s=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06682b0a-0930-4edf-8fac-59ae27375f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "###### Stage 9: What are some issues with the process that has been shown so far?\n",
    "######\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56a833-3c77-4e97-b057-d0d1f76847fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some questions you may want to think about:\n",
    "#Is the data being used to calculate the score fair?\n",
    "#How could we deal with the negative predictions that are beinng made?\n",
    "#How could we use train and test splitting?\n",
    "#When would we want to use a validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512401ad-1a9e-4f20-a91f-f1b3215f6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#However this is for data that the model has already seen, it was trained on this data.\n",
    "#To get a fair representation of the model performance we want to test it on data \n",
    "\n",
    "\n",
    "######\n",
    "###### Stage 10: Creating a Train, and Test Set\n",
    "######\n",
    "######\n",
    "airPollutionDataTrainingData = airPollutionData[airPollutionData[\"Timestamp\"] < '2018-9-1']\n",
    "display(airPollutionDataTrainingData.shape)\n",
    "airPollutionDataTestData = airPollutionData[airPollutionData[\"Timestamp\"] >= '2018-9-1']\n",
    "display(airPollutionDataTestData.shape)\n",
    "display(airPollutionData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804e2b3-08ce-4588-8ba3-f1c36baa6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here to use the train and test split, investigate further the true performance of the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0729e-bc7d-4d54-a3f2-4496be82805c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210aa6a5-1401-49cb-81f0-5cde234288cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
